use(require("atomy"))

lexer = require(File expand-path("../lexer", __FILE__))

const-set(.Lexer, lexer Lexer)
Lexer const-set(.Matcher, lexer Matcher)
Lexer const-set(.State, require(File expand-path("../state", __FILE__)))
Lexer const-set(.Token, require(File expand-path("../token", __FILE__)))

macro(lexer: ~*body):
  `(Lexer class:
      @matchers = Hash new
      @info = Hash new

      ~*body)

def(short-name(["name", "constant"])): "no"
def(short-name(["name", "entity"])): "ni"
def(short-name(["name", "property"])): "py"
def(short-name(["literal", b])): short-name([b])
def(short-name([a, "other"])): short-name([a]) + "x"
def(short-name([a, "error"])): short-name([a]) + "r"
def(short-name([a, "single"])): short-name([a]) + "1"
def(short-name([a, "double"])): short-name([a]) + "2"
def(short-name([a, b])): short-name([a]) + short-name([b])
def(short-name(["error"])): "err"
def(short-name(["number"])): "m"
def(short-name([x])): x slice(0, 1)
def(short-name(_ . xs)): short-name(xs)

fn(str(x)): Atomy Grammar AST StringLiteral new(x)

def(type-from(x & Atomy Grammar AST Word)):
  `(Token Tagged new(~str(short-name([x text to-s]))))

def(type-from(`((~a). ~(b)))):
  tag = short-name([
    a text to-s
    b text to-s])
  `(Token Tagged new(~str(tag)))

def(type-from(`(~_ (~a). ~(b)))):
  tag = short-name([
    a text to-s
    b text to-s])
  `(Token Tagged new(~str(tag)))

def(type-from(`(by-groups(~*args)))):
  `(Token ByGroups new([~*(args collect [a]: type-from(a))]))

def(type-from(`(using(~who)))):
  `(Token Using new(~who))

def(type-from(x)): raise("unknown match type: " + x inspect)

def(regexp-from(x)):
  `([x]: Regexp new(
      x source
      x options | @info fetch(.flags)
    ); call(~x))

def(state-from('pop)): '(State Pop new)
def(state-from(`(pop(~n)))): `(State PopNum new(~n))
def(state-from('push)): '(State Push new)
def(state-from(`(do-all(~*args)))):
  `(State DoAll new([~*(args collect [a]: state-from(a))]))
def(state-from(`(combined(~*args)))):
  all = args reverse collect [a]:
    `(@matchers fetch(.~a))

  `(State Combined new([~*all]))
def(state-from(`(go-to(~n)))):
  `(State GoTo new(@matchers, .~n))
def(state-from(x)):
  raise("unknown state: " + x inspect)


macro(lex(~name): ~*tokens):
  `(lex(~name) []: ~*tokens)

macro(lex(~name) [~*args]: ~*tokens):
  branches = []

  body = []

  tokens each [c]:
    c match:
      -- implicit continue state
      `(~x is(~y)):
        branches <<
          `(Matcher new(
              ~(regexp-from(x))
              ~(type-from(y))
              State Continue new
            ))

      -- specifying a state
      `(~x is(~y) -> ~z):
        branches <<
          `(Matcher new(
              ~(regexp-from(x))
              ~(type-from(y))
              ~(state-from(z))
            ))

      -- goto shortcut
      `(~x is(~y) => ~z):
        branches <<
          `(Matcher new(
              ~(regexp-from(x))
              ~(type-from(y))
              State GoTo new(@matchers, .~z)
            ))

      `(any-of(~any)):
        branches <<
          `(@matchers fetch(.~any) call) -- TODO: parameterization?

      _:
        body << c

  body << `([~*branches] flatten)

  `(@matchers[.~name] = proc [~*args]:
      ~*body)
