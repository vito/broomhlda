class(NoMatchFor < Error):
  initialize(@input) := #ok

  export: message :=
    "no matchers succeeded for: " +
      @input slice(0, 50) inspect + " [...]"


symbols(try-all, tokens)

module(HL):
  data(Object):
    Matcher(@regexp, @type, @next)

  module(Lexers):
    class(Lexer):
      define(initialize(input)):
        @input = input dup

        @state = [
          class matchers fetch(class info fetch(#start)) call
        ] -- [Matcher]

        @lexed = [] -- [Token]

      -- run the lexer until the input is empty, yielding
      -- the lexed tokens
      define(run):
        until(@input empty?):
          try-all(@state last)

        @lexed

      -- go through matchers until one matches the immediate
      -- next input. if none match, try again, but allowing
      -- matches past the start. see #try-all-first.
      try-all(ms) := do:
        closest = nil
        worked = nil

        ms each (m):
          m regexp match(@input) match:
            -- only allow a match that's at the start of the input
            (d: MatchData ? pre-match empty?) -> do:
              closest =! nil
              worked =! nil

              @input slice!(0, d to-s size)

              m next apply(@state, d)

              tokens(d, m type)

              return(true) -- o.

            -- matched, but not at the start; set the closest match
            -- information in case of failure
            (d: MatchData ?
              closest nil? ||
                pre-match size < closest pre-match size) -> do:
              closest =! d
              worked =! m

        if(closest nil?)
          then: error(NoMatchFor new(@input))
          else:
            skipped = closest pre-match
            @input = closest post-match

            worked next apply(@state, closest)

            @lexed << HL::Tokens::Token new(
              HL::Tokens::Tagged new("err")
              skipped
            )

            tokens(closest, worked type)

            return(false)

      -- TODO: Using
      tokens(data, gs: HL::Tokens::ByGroups) :=
        gs types zip(data to-a drop(1)) ([t, d]):
          when(t nil? || d nil?):
            return(nil)

          @lexed << HL::Tokens::Token new(t, d)

      tokens(data, t: HL::Tokens::Tagged) :=
        @lexed << HL::Tokens::Token new(t, data to-s)

      class(<< self):
        attr-accessor(#matchers, #info)

        name(&x) :=
          @info [#name] = x call

        aliases(&x) :=
          @info [#aliases] = Array(x call)

        extensions(&x) :=
          @info [#extensions] = Array(x call)

        mimetypes(&x) :=
          @info [#mimetypes] = Array(x call)

        start(&x) :=
          @info [#start] = x call

        flags(&x) :=
          @info [#flags] = x call
